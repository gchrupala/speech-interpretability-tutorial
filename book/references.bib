---
---

@inproceedings{bentumProcessingStressEndEnd2024,
	title = {The {Processing} of {Stress} in {End}-to-{End} {Automatic} {Speech} {Recognition} {Models}},
	doi = {10.21437/Interspeech.2024-44},
	booktitle = {Interspeech 2024},
	author = {Bentum, Martijn and Bosch, Louis ten and Lentz, Tom},
	year = {2024},
	pages = {2350--2354},
}

@inproceedings{shen-etal-2024-encoding,
    title = "Encoding of lexical tone in self-supervised models of spoken language",
    author = "Shen, Gaofei  and
      Watkins, Michaela  and
      Alishahi, Afra  and
      Bisazza, Arianna  and
      Chrupa{\l}a, Grzegorz",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2024.naacl-long.239",
    pages = "4250--4261",
    abstract = "Interpretability research has shown that self-supervised Spoken LanguageModels (SLMs) encode a wide variety of features in human speech from theacoustic, phonetic, phonological, syntactic and semantic levels, to speakercharacteristics. The bulk of prior research on representations of phonologyhas focused on segmental features such as phonemes; the encoding ofsuprasegmental phonology (such as tone and stress patterns) in SLMs is not yetwell understood. Tone is a suprasegmental feature that is present in more thanhalf of the world{'}s languages. This paper aims to analyze the tone encodingcapabilities of SLMs, using Mandarin and Vietnamese as case studies. We showthat SLMs encode lexical tone to a significant degree even when they aretrained on data from non-tonal languages. We further find that SLMs behavesimilarly to native and non-native human participants in tone and consonantperception studies, but they do not follow the same developmental trajectory.",
}

@inproceedings{deheerklootsWhatSelfsupervisedSpeech2025,
	title = {What do self-supervised speech models know about {Dutch}? {Analyzing} advantages of language-specific pre-training},
	shorttitle = {What do self-supervised speech models know about {Dutch}?},
	doi = {10.48550/arXiv.2506.00981},
	author = {{de Heer Kloots}, Marianne and Mohebbi, Hosein and Pouw, Charlotte and Shen, Gaofei and Zuidema, Willem and Bentum, Martijn},
	year = {2025},
	booktitle = {Interspeech 2025}
}

@inproceedings{cormacenglishDomainInformedProbingWav2vec2022,
	address = {Seattle, Washington},
	title = {Domain-{Informed} {Probing} of wav2vec 2.0 {Embeddings} for {Phonetic} {Features}},
	doi = {10.18653/v1/2022.sigmorphon-1.9},
	booktitle = {Proceedings of the 19th {SIGMORPHON} {Workshop} on {Computational} {Research} in {Phonetics}, {Phonology}, and {Morphology}},
	publisher = {Association for Computational Linguistics},
	author = {Cormac English, Patrick and Kelleher, John D. and Carson-Berndsen, Julie},
	editor = {Nicolai, Garrett and Chodroff, Eleanor},
	month = jul,
	year = {2022},
	pages = {83--91}
}

@inproceedings{shenWaveSyntaxProbing2023a,
	title = {Wave to {Syntax}: {Probing} spoken language models for syntax},
	shorttitle = {Wave to {Syntax}},
	doi = {10.21437/Interspeech.2023-679},
	booktitle = {Interspeech 2023},
	author = {Shen, Gaofei and Alishahi, Afra and Bisazza, Arianna and Chrupała, Grzegorz},
	year = {2023},
	pages = {1259--1263}
}

@inproceedings{chrupala-etal-2020-analyzing,
    title = "Analyzing analytical methods: The case of phonology in neural models of spoken language",
    author = "Chrupa{\l}a, Grzegorz  and
      Higy, Bertrand  and
      Alishahi, Afra",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2020.acl-main.381",
    pages = "4146--4156",
    abstract = "Given the fast development of analysis techniques for NLP and speech processing systems, few systematic studies have been conducted to compare the strengths and weaknesses of each method. As a step in this direction we study the case of representations of phonology in neural network models of spoken language. We use two commonly applied analytical techniques, diagnostic classifiers and representational similarity analysis, to quantify to what extent neural activation patterns encode phonemes and phoneme sequences. We manipulate two factors that can affect the outcome of analysis. First, we investigate the role of learning by comparing neural activations extracted from trained versus randomly-initialized models. Second, we examine the temporal scope of the activations by probing both local activations corresponding to a few milliseconds of the speech signal, and global activations pooled over the whole utterance. We conclude that reporting analysis results with randomly initialized models is crucial, and that global-scope methods tend to yield more consistent and interpretable results and we recommend their use as a complement to local-scope diagnostic methods.",
}

@inproceedings{Pasad2021,
  author={Pasad, Ankita and Chou, Ju-Chieh and Livescu, Karen},
  booktitle={2021 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)}, 
  title={Layer-Wise Analysis of a Self-Supervised Speech Representation Model}, 
  year={2021},
  volume={},
  number={},
  pages={914-921},
  doi={10.1109/ASRU51503.2021.9688093}
}

@InProceedings{pmlr-v97-kornblith19a,
  title = 	 {Similarity of Neural Network Representations Revisited},
  author =       {Kornblith, Simon and Norouzi, Mohammad and Lee, Honglak and Hinton, Geoffrey},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {3519--3529},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/kornblith19a/kornblith19a.pdf},
  url = 	 {https://proceedings.mlr.press/v97/kornblith19a.html}
}

@inproceedings{deheerklootsHumanlikeLinguisticBiases2024,
	title = {Human-like {Linguistic} {Biases} in {Neural} {Speech} {Models}: {Phonetic} {Categorization} and {Phonotactic} {Constraints} in {Wav2Vec2}.0},
	shorttitle = {Human-like {Linguistic} {Biases} in {Neural} {Speech} {Models}},
	doi = {10.21437/Interspeech.2024-2490},
	booktitle = {Interspeech 2024},
	author = {{de Heer Kloots}, Marianne and Zuidema, Willem},
	year = {2024},
	pages = {4593--4597},
}

@inproceedings{langedijkDecoderLensLayerwiseInterpretation2024,
	address = {Mexico City, Mexico},
	title = {{DecoderLens}: {Layerwise} {Interpretation} of {Encoder}-{Decoder} {Transformers}},
	shorttitle = {{DecoderLens}},
	doi = {10.18653/v1/2024.findings-naacl.296},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {NAACL} 2024},
	publisher = {Association for Computational Linguistics},
	author = {Langedijk, Anna and Mohebbi, Hosein and Sarti, Gabriele and Zuidema, Willem and Jumelet, Jaap},
	editor = {Duh, Kevin and Gomez, Helena and Bethard, Steven},
	month = jun,
	year = {2024},
	pages = {4764--4780}
}

@phdthesis{schatz2016,
  TITLE = {{ABX-Discriminability Measures and Applications}},
  AUTHOR = {Schatz, Thomas},
  URL = {https://hal.science/tel-01407461},
  SCHOOL = {{Universit{\'e} Paris 6 (UPMC)}},
  YEAR = {2016},
  MONTH = Sep,
  KEYWORDS = { speech ; ABX discriminability ;  development ;  phonetic categories ;  modeling ;  cognitive science ;  sciences cognitives ;  {\'e}valuation ;  parole ;  cat{\'e}gories phon{\'e}tiques ;  mod{\'e}lisation ; discriminabilit{\'e} ABX},
  TYPE = {Theses},
  PDF = {https://hal.science/tel-01407461v1/file/Schatz2016.pdf},
  HAL_ID = {tel-01407461},
  HAL_VERSION = {v1},
}


@article{algayresDPParseFindingWord2022,
	title = {{DP}-{Parse}: {Finding} {Word} {Boundaries} from {Raw} {Speech} with an {Instance} {Lexicon}},
	volume = {10},
	issn = {2307-387X},
	shorttitle = {{DP}-{Parse}},
	doi = {10.1162/tacl_a_00505},
	abstract = {Finding word boundaries in continuous speech is challenging as there is little or no equivalent of a ‘space’ delimiter between words. Popular Bayesian non-parametric models for text segmentation (Goldwater et al., 2006, 2009) use a Dirichlet process to jointly segment sentences and build a lexicon of word types. We introduce DP-Parse, which uses similar principles but only relies on an instance lexicon of word tokens, avoiding the clustering errors that arise with a lexicon of word types. On the Zero Resource Speech Benchmark 2017, our model sets a new speech segmentation state-of-the-art in 5 languages. The algorithm monotonically improves with better input representations, achieving yet higher scores when fed with weakly supervised inputs. Despite lacking a type lexicon, DP-Parse can be pipelined to a language model and learn semantic and syntactic representations as assessed by a new spoken word embedding benchmark. 1},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Algayres, Robin and Ricoul, Tristan and Karadayi, Julien and Laurençon, Hugo and Zaiem, Salah and Mohamed, Abdelrahman and Sagot, Benoît and Dupoux, Emmanuel},
	month = sep,
	year = {2022},
	pages = {1051--1065},
	file = {Full Text PDF:/Users/mdhk/Zotero/storage/7HBNPVET/Algayres et al. - 2022 - DP-Parse Finding Word Boundaries from Raw Speech .pdf:application/pdf;Snapshot:/Users/mdhk/Zotero/storage/FKH8ZIKP/DP-Parse-Finding-Word-Boundaries-from-Raw-Speech.html:text/html},
}


@misc{seysselDiscriminatingFormMeaning2025,
	title = {Discriminating {Form} and {Meaning} in {Multilingual} {Models} with {Minimal}-{Pair} {ABX} {Tasks}},
	doi = {10.48550/arXiv.2505.17747},
	abstract = {We introduce a set of training-free ABX-style discrimination tasks to evaluate how multilingual language models represent language identity (form) and semantic content (meaning). Inspired from speech processing, these zero-shot tasks measure whether minimal differences in representation can be reliably detected. This offers a flexible and interpretable alternative to probing. Applied to XLM-R (Conneau et al, 2020) across pretraining checkpoints and layers, we find that language discrimination declines over training and becomes concentrated in lower layers, while meaning discrimination strengthens over time and stabilizes in deeper layers. We then explore probing tasks, showing some alignment between our metrics and linguistic learning performance. Our results position ABX tasks as a lightweight framework for analyzing the structure of multilingual representations.},
	publisher = {arXiv},
	author = {Seyssel, Maureen de and Chi, Jie and Seto, Skyler and Hoeve, Maartje ter and Fedzechkina, Masha and Schluter, Natalie},
	month = jun,
	year = {2025},
	note = {arXiv:2505.17747 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Preprint PDF:/Users/mdhk/Zotero/storage/QINQE22C/Seyssel et al. - 2025 - Discriminating Form and Meaning in Multilingual Mo.pdf:application/pdf;Snapshot:/Users/mdhk/Zotero/storage/AF5CLN5Y/2505.html:text/html},
}

@inproceedings{pengWordDiscoveryVisually2022a,
	title = {Word {Discovery} in {Visually} {Grounded}, {Self}-{Supervised} {Speech} {Models}},
	doi = {10.21437/Interspeech.2022-10652},
	booktitle = {Interspeech 2022},
	author = {Peng, Puyuan and Harwath, David},
	year = {2022},
	pages = {2823--2827}
}
@inproceedings{a-shams-etal-2024-uncovering,
    title = "Uncovering Syllable Constituents in the Self-Attention-Based Speech Representations of Whisper",
    author = "A Shams, Erfan  and
      Gessinger, Iona  and
      Carson-Berndsen, Julie",
    editor = "Belinkov, Yonatan  and
      Kim, Najoung  and
      Jumelet, Jaap  and
      Mohebbi, Hosein  and
      Mueller, Aaron  and
      Chen, Hanjie",
    booktitle = "Proceedings of the 7th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP",
    month = nov,
    year = "2024",
    address = "Miami, Florida, US",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2024.blackboxnlp-1.16",
    pages = "238--247",
    abstract = "As intuitive units of speech, syllables have been widely studied in linguistics. A syllable can be defined as a three-constituent unit with a vocalic centre surrounded by two (in some languages optional) consonant clusters. Syllables are also used to design automatic speech recognition (ASR) models. The significance of knowledge-driven syllable-based tokenisation in ASR over data-driven byte-pair encoding has often been debated. However, the emergence of transformer-based ASR models employing self-attention (SA) overshadowed this debate. These models learn the nuances of speech from large corpora without prior knowledge of the domain; yet, they are not interpretable by design. Consequently, it is not clear if the recent performance improvements are related to the extraction of human-interpretable knowledge. We probe such models for syllable constituents and use an SA head pruning method to assess the relevance of the SA weights. We also investigate the role of vowel identification in syllable constituent probing. Our findings show that the general features of syllable constituents are extracted in the earlier layers of the model and the syllable-related features mostly depend on the temporal knowledge incorporated in specific SA heads rather than on vowel identification."
}

@inproceedings{mohebbiHomophoneDisambiguationReveals2023a,
	address = {Singapore},
	title = {Homophone {Disambiguation} {Reveals} {Patterns} of {Context} {Mixing} in {Speech} {Transformers}},
	doi = {10.18653/v1/2023.emnlp-main.513},
	booktitle = {Proceedings of the 2023 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Mohebbi, Hosein and Chrupała, Grzegorz and Zuidema, Willem and Alishahi, Afra},
	editor = {Bouamor, Houda and Pino, Juan and Bali, Kalika},
	month = dec,
	year = {2023},
	pages = {8249--8260}
}

@inproceedings{fucciExplainabilitySpeechModels2024,
  title = {Explainability for {{Speech Models}}: {{On}} the {{Challenges}} of {{Acoustic Feature Selection}}},
  shorttitle = {Explainability for {{Speech Models}}},
  booktitle = {Proceedings of the 10th {{Italian Conference}} on {{Computational Linguistics}} ({{CLiC-it}} 2024)},
  author = {Fucci, Dennis and Savoldi, Beatrice and Gaido, Marco and Negri, Matteo and Cettolo, Mauro and Bentivogli, Luisa},
  editor = {Dell'Orletta, Felice and Lenci, Alessandro and Montemagni, Simonetta and Sprugnoli, Rachele},
  year = {2024},
  month = dec,
  pages = {373--381},
  publisher = {CEUR Workshop Proceedings},
  address = {Pisa, Italy},
  urldate = {2025-04-12},
  isbn = {979-12-210-7060-6}
}

@inproceedings{shenReliabilityFeatureAttribution2025,
	title = {On the reliability of feature attribution methods for speech classification},
	doi = {10.48550/arXiv.2505.16406},
	abstract = {As the capabilities of large-scale pre-trained models evolve, understanding the determinants of their outputs becomes more important. Feature attribution aims to reveal which parts of the input elements contribute the most to model outputs. In speech processing, the unique characteristics of the input signal make the application of feature attribution methods challenging. We study how factors such as input type and aggregation and perturbation timespan impact the reliability of standard feature attribution methods, and how these factors interact with characteristics of each classification task. We find that standard approaches to feature attribution are generally unreliable when applied to the speech domain, with the exception of word-aligned perturbation methods when applied to word-based classification tasks.},
	booktitle = {Interspeech 2025},
	author = {Shen, Gaofei and Mohebbi, Hosein and Bisazza, Arianna and Alishahi, Afra and Chrupała, Grzegorz},
	year = {2025},
}

@inproceedings{prasadHowAccentsConfound2020,
	address = {Online},
	title = {How {Accents} {Confound}: {Probing} for {Accent} {Information} in {End}-to-{End} {Speech} {Recognition} {Systems}},
	shorttitle = {How {Accents} {Confound}},
	url = {https://aclanthology.org/2020.acl-main.345},
	doi = {10.18653/v1/2020.acl-main.345},
	urldate = {2024-10-10},
	booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Prasad, Archiki and Jyothi, Preethi},
	editor = {Jurafsky, Dan and Chai, Joyce and Schluter, Natalie and Tetreault, Joel},
	month = jul,
	year = {2020},
	pages = {3739--3753}
}

@inproceedings{guptaPhonemeDiscretizedSaliency2024,
	title = {Phoneme {Discretized} {Saliency} {Maps} for {Explainable} {Detection} of {AI}-{Generated} {Voice}},
	doi = {10.21437/Interspeech.2024-632},
	booktitle = {Interspeech 2024},
	author = {Gupta, Shubham and Ravanelli, Mirco and Germain, Pascal and Subakan, Cem},
	year = {2024},
	pages = {3295--3299}
}

@inproceedings{wuExplanationsforASR2023,
  author={Wu, Xiaoliang and Bell, Peter and Rajan, Ajitha},
  booktitle={ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Explanations for Automatic Speech Recognition}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  keywords={Adaptation models;Neural networks;Machine learning;Signal processing;Quality assessment;Internet;Speech processing;Explanation;Automatic Speech Recognition},
  doi={10.1109/ICASSP49357.2023.10094635}
}

@inproceedings{pastor-etal-2024-explaining,
    title = "Explaining Speech Classification Models via Word-Level Audio Segments and Paralinguistic Features",
    author = "Pastor, Eliana  and
      Koudounas, Alkis  and
      Attanasio, Giuseppe  and
      Hovy, Dirk  and
      Baralis, Elena",
    editor = "Graham, Yvette  and
      Purver, Matthew",
    booktitle = "Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = mar,
    year = "2024",
    address = "St. Julian{'}s, Malta",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.eacl-long.136/",
    pages = "2221--2238",
    abstract = "Predictive models make mistakes and have biases. To combat both, we need to understand their predictions.Explainable AI (XAI) provides insights into models for vision, language, and tabular data. However, only a few approaches exist for speech classification models. Previous works focus on a selection of spoken language understanding (SLU) tasks, and most users find their explanations challenging to interpret.We propose a novel approach to explain speech classification models. It provides two types of insights. (i) Word-level. We measure the impact of each audio segment aligned with a word on the outcome. (ii) Paralinguistic. We evaluate how non-linguistic features (e.g., prosody and background noise) affect the outcome if perturbed.We validate our approach by explaining two state-of-the-art SLU models on two tasks in English and Italian. We test their plausibility with human subject ratings. Our results show that the explanations correctly represent the model{'}s inner workings and are plausible to humans."
}

@misc{yangUnderstandingSelfAttentionSelfSupervised2020a,
  title = {Understanding {Self}-{Attention} of {Self}-{Supervised} {Audio} {Transformers}},
  url = {http://arxiv.org/abs/2006.03265},
  doi = {10.48550/arXiv.2006.03265},
  abstract = {Self-supervised Audio Transformers (SAT) enable great success in many downstream speech applications like ASR, but how they work has not been widely explored yet. In this work, we present multiple strategies for the analysis of attention mechanisms in SAT. We categorize attentions into explainable categories, where we discover each category possesses its own unique functionality. We provide a visualization tool for understanding multi-head self-attention, importance ranking strategies for identifying critical attention, and attention refinement techniques to improve model performance.},
  urldate = {2025-08-15},
  publisher = {arXiv},
  author = {Yang, Shu-wen and Liu, Andy T. and Lee, Hung-yi},
  month = aug,
  year = {2020},
}


@article{shimUNDERSTANDINGROLESELF2022,
  title = {Understanding the Role of Self-Attention for Speech Understanding},
  abstract = {Self-attention (SA) is a critical component of Transformer neural networks that have succeeded in automatic speech recognition (ASR). In this paper, we analyze the role of SA in Transformer-based ASR models for not only understanding the mechanism of improved recognition accuracy but also lowering the computational complexity. We reveal that SA performs two distinct roles: phonetic and linguistic localization. Especially, we show by experiments that phonetic localization in the lower layers extracts phonologically meaningful features from speech and reduces the phonetic variance in the utterance for proper linguistic localization in the upper layers. From this understanding, we discover that attention maps can be reused as long as their localization capability is preserved. To evaluate this idea, we implement the layer-wise attention map reuse on real GPU platforms and achieve up to 1.96 times speedup in inference and 33\% savings in training time with noticeably improved ASR performance for the challenging benchmark on LibriSpeech dev/test-other dataset.},
  language = {en},
  author = {Shim, Kyuhong and Choi, Jungwook and Sung, Wonyong},
  year = {2022},
}


@inproceedings{alastrueyLocalityAttentionDirect2022,
  address = {Dublin, Ireland},
  title = {On the {Locality} of {Attention} in {Direct} {Speech} {Translation}},
  url = {https://aclanthology.org/2022.acl-srw.32/},
  doi = {10.18653/v1/2022.acl-srw.32},
  booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}: {Student} {Research} {Workshop}},
  publisher = {Association for Computational Linguistics},
  author = {Alastruey, Belen and Ferrando, Javier and Gállego, Gerard I. and Costa-jussà, Marta R.},
  editor = {Louvan, Samuel and Madotto, Andrea and Madureira, Brielen},
  year = {2022},
  pages = {402--412}
}


@misc{audhkhasiAnalysisSelfAttentionHead2022,
  title = {Analysis of {Self}-{Attention} {Head} {Diversity} for {Conformer}-based {Automatic} {Speech} {Recognition}},
  url = {http://arxiv.org/abs/2209.06096},
  doi = {10.48550/arXiv.2209.06096},
  author = {Audhkhasi, Kartik and Huang, Yinghui and Ramabhadran, Bhuvana and Moreno, Pedro J.},
  year = {2022},
}


@inproceedings{kobayashiAttentionNotOnly2020a,
  address = {Online},
  title = {Attention is {Not} {Only} a {Weight}: {Analyzing} {Transformers} with {Vector} {Norms}},
  shorttitle = {Attention is {Not} {Only} a {Weight}},
  url = {https://aclanthology.org/2020.emnlp-main.574/},
  doi = {10.18653/v1/2020.emnlp-main.574},
  publisher = {Association for Computational Linguistics},
  author = {Kobayashi, Goro and Kuribayashi, Tatsuki and Yokoi, Sho and Inui, Kentaro},
  editor = {Webber, Bonnie and Cohn, Trevor and He, Yulan and Liu, Yang},
  year = {2020},
  pages = {7057--7075}
}
